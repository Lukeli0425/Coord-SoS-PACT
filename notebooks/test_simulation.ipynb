{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.colors import Normalize\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "from kwave.ktransducer import kWaveGrid\n",
    "from models.ADMM import ADMM_Batched\n",
    "from models.APACT import APACT\n",
    "from models.DAS import DAS, DAS_dual\n",
    "from models.Joint_Recon import Joint_Recon\n",
    "from models.PACT import TF_PACT, Wavefront_SoS\n",
    "from models.Wiener import Wiener_Batched\n",
    "from utils.data import *\n",
    "from utils.reconstruction import *\n",
    "from utils.simulations import get_water_SoS\n",
    "from utils.visualization import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_path = '../data/'\n",
    "results_path = '../results/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Sinogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinogram = load_mat(os.path.join(data_path, 'sinogram_simulation_easy.mat'))\n",
    "sinogram_uniform = load_mat(os.path.join(data_path, 'sinogram_simulation_uniform.mat'))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(sinogram, cmap='gray')\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(sinogram_uniform, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SoS = load_mat(os.path.join(data_path, 'SoS_easy.mat'))\n",
    "# SoS_error = load_mat(os.path.join(data_path, 'SoS_error.mat'))\n",
    "SoS_error = load_mat(os.path.join(results_path, 'SoS_jr.mat'))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(11, 6))\n",
    "norm = Normalize(vmax=1600, vmin=1500)\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('True SoS', fontsize=14)\n",
    "plt.imshow(SoS, norm=norm, cmap='magma')\n",
    "plt.axis('off')\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "plt.title('SoS with Error', fontsize=14)\n",
    "plt.imshow(SoS_error, norm=norm, cmap='magma')\n",
    "plt.axis('off')\n",
    "cax = fig.add_axes([ax.get_position().x1+0.03, ax.get_position().y0, 0.02, ax.get_position().height])\n",
    "cb = plt.colorbar(cax=cax, norm=norm)\n",
    "cb.ax.set_yticks([1500, 1520, 1540, 1560, 1580, 1600])\n",
    "cb.ax.tick_params(labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations\n",
    "\n",
    "First, we need to define the size and resolution of the image. We also calculate the X and Y coordinates of each pixels in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx, Ny = 560, 560\n",
    "dx, dy = 4e-5, 4e-5\n",
    "kgrid = kWaveGrid([Nx, Ny], [dx, dy])\n",
    "x_vec, y_vec = kgrid.x_vec, kgrid.y_vec\n",
    "l = 3.2e-3 # Patch size [m]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define parameters of the single-body SoS for the following wavefront and PSF calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 9.8e-3              # Radius of single body [m].\n",
    "T = 26.0                # Water temperature [C].\n",
    "v0 = get_water_SoS(T)   # Background SoS [m/s].\n",
    "v1 = 1558#1567.3             # Avergae SoS in single body [m/s].\n",
    "print(v0, v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the gaussian kernel which smooths the image boundaries when merging image patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwhm = 1.5e-3 # [m]\n",
    "sigma = fwhm / 4e-5 / np.sqrt(2*np.log(2))\n",
    "gaussian_window = torch.tensor(gaussian_kernel(sigma, 80)).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the delay-and-sum model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "das = DAS(R_ring=0.05, N_transducer=512, T_sample=1/40e6, x_vec=x_vec, y_vec=y_vec, mode='zero')\n",
    "das.cuda()\n",
    "das.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform SoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    gt = das(sinogram=torch.tensor(sinogram_uniform).cuda(), \n",
    "             v0=torch.tensor(v0).cuda(),\n",
    "             d_delay=torch.zeros(1).cuda(),\n",
    "             ring_error=torch.zeros(1).cuda()).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mat(os.path.join(results_path, 'gt_simulation.mat'), gt.swapaxes(0,1), 'img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventional DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    rec_das = das(sinogram=torch.tensor(sinogram).cuda(),\n",
    "                  v0=torch.tensor(1510.5).cuda(),\n",
    "                  d_delay=torch.zeros(1).cuda(),\n",
    "                  ring_error=torch.zeros(1).cuda()).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mat(os.path.join(results_path, 'das_simulation_easy.mat'), rec_das.swapaxes(0,1), 'img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dual SoS DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "das_dual = DAS_dual(R_ring=0.05, N_transducer=512, T_sample=1/40e6, x_vec=x_vec, y_vec=y_vec, R_body=R, center=(0.0, 0.0), mode='zero')\n",
    "das_dual.cuda()\n",
    "das_dual.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    rec_das_dual = das_dual(sinogram=torch.tensor(sinogram).cuda(),\n",
    "                            v0=torch.tensor(v0).cuda(),\n",
    "                            v1=torch.tensor(v1).cuda(),\n",
    "                            d_delay=torch.zeros(1).cuda(), \n",
    "                            ring_error=torch.zeros(1).cuda()).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mat(os.path.join(results_path, 'das_dual_simulation_easy.mat'), rec_das_dual.swapaxes(0,1), 'img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delays_apact = np.arange(-8e-4, 8e-4, 0.5e-4) # Delay distances [m].\n",
    "\n",
    "# apact = APACT(delays=delays_apact, dc_range=[-2e-4, 1.6e-4], amp=3.2e-4, step=4e-5, data_path='./TF_simulation/', device=device)\n",
    "# apact.cuda()\n",
    "# apact.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_stack = []\n",
    "# with torch.no_grad():\n",
    "#     for d_delay in tqdm(delays_apact):\n",
    "#         recon = das(sinogram=torch.tensor(sinogram).cuda(), \n",
    "#                     v0=torch.tensor(1510.5).cuda(),\n",
    "#                     d_delay=torch.tensor(d_delay).cuda(),\n",
    "#                     ring_error=torch.zeros(1).cuda())\n",
    "#         img_stack.append(recon)\n",
    "# img_stack = torch.stack(img_stack, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def deconv_full_apact(model, img_stack, gaussian_window):\n",
    "#     rec_apact = torch.zeros_like(img_stack[0]).cuda()\n",
    "#     with torch.no_grad():\n",
    "#         for idx in tqdm(range(625)):\n",
    "#             i, j = idx // 25, idx % 25\n",
    "#             obs = img_stack[:,20*i:20*i+80, 20*j:20*j+80] * gaussian_window\n",
    "#             obs = obs.unsqueeze(0).cuda()\n",
    "#             rec, _, _, _ = model(obs)\n",
    "#             rec_apact[20*i:20*i+80, 20*j:20*j+80] += rec.squeeze(0).squeeze(0)\n",
    "#     return rec_apact.detach().cpu().numpy()\n",
    "\n",
    "# rec_apact = deconv_full_apact(apact, img_stack, gaussian_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_mat(os.path.join(results_path, 'apact_simulation_easy.mat'), rec_apact.swapaxes(0,1), 'img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deconvolution with Single Body PSFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_delays = 32\n",
    "delays = np.linspace(-8e-4, 8e-4, n_delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_stack = []\n",
    "with torch.no_grad():\n",
    "    for d_delay in tqdm(delays):\n",
    "        recon = das(sinogram=torch.tensor(sinogram).cuda(), \n",
    "                    v0=torch.tensor(v0).cuda(),\n",
    "                    d_delay=torch.tensor(d_delay).cuda(),\n",
    "                    ring_error=torch.zeros(1).cuda())\n",
    "        img_stack.append(recon)\n",
    "img_stack = torch.stack(img_stack, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv_full(img_stack, SoS, gaussian_window, delays, attention='uniform'):\n",
    "    wavefront_sos = Wavefront_SoS(R, v0, x_vec, y_vec, n_points=180)\n",
    "    wavefront_sos.cuda()\n",
    "    wavefront_sos.eval()\n",
    "    \n",
    "    tf_pact = TF_PACT(n_points=160, l=6.4e-3, n_delays=delays.shape[0])\n",
    "    tf_pact.cuda()\n",
    "    tf_pact.eval()\n",
    "\n",
    "    wiener = Wiener_Batched(lam=0e-3, order=1.2, device=device)\n",
    "    wiener.cuda()\n",
    "    wiener.eval()\n",
    "    \n",
    "    img_stack /= img_stack.abs().mean()\n",
    "    rec_full = torch.zeros_like(img_stack[0]).cuda()\n",
    "    SoS = torch.tensor(SoS, dtype=torch.float64).cuda()\n",
    "    with torch.no_grad():\n",
    "        for idx in tqdm(range(625)):\n",
    "            i, j = idx // 25, idx % 25\n",
    "            x, y = (j-12)*l / 4, (12-i)*l / 4\n",
    "            thetas, wfs = wavefront_sos(torch.tensor(x).cuda(), torch.tensor(y).cuda(), SoS)\n",
    "            tf = tf_pact(torch.tensor(delays).cuda().view(1,-1,1,1), thetas, wfs).squeeze(0)\n",
    "            obs = img_stack[:,20*i:20*i+80, 20*j:20*j+80]\n",
    "            _, C0 = get_r_C0(i, j, R, l, v0, v1)\n",
    "            weights = torch.tensor(get_weights(C0, delays, attention)).cuda()\n",
    "            print(tf.shape, obs.shape)\n",
    "            obs, tf = obs * torch.sqrt(weights), tf * torch.sqrt(weights) # Apply attention weights to different channels.\n",
    "            print(tf.shape, obs.shape)\n",
    "            obs = obs.unsqueeze(0) * gaussian_window\n",
    "            rec = wiener(obs, tf)\n",
    "            rec_full[20*i:20*i+80, 20*j:20*j+80] += rec.squeeze(0).squeeze(0)\n",
    "    return rec_full.detach().cpu().numpy()\n",
    "\n",
    "rec_deconv = deconv_full(img_stack, SoS, gaussian_window, delays)\n",
    "rec_jr = deconv_full(img_stack, SoS_error, gaussian_window, delays)\n",
    "rec_deconv_onehot = deconv_full(img_stack, SoS, gaussian_window, delays, 'onehot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mat(os.path.join(results_path, 'deconv_simulation_easy.mat'), rec_deconv.swapaxes(0,1), 'img')\n",
    "save_mat(os.path.join(results_path, 'jr_simulation_easy.mat'), rec_jr.swapaxes(0,1), 'img')\n",
    "save_mat(os.path.join(results_path, 'deconv_onehot_simulation_easy.mat'), rec_deconv_onehot.swapaxes(0,1), 'img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Load and normalize images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP_img = load_mat(os.path.join(data_path, 'IP.mat'))\n",
    "gt = load_mat(os.path.join(results_path, 'gt_simulation.mat'))\n",
    "rec_das = load_mat(os.path.join(results_path, 'das_simulation_easy.mat'))\n",
    "rec_das_dual = load_mat(os.path.join(results_path, 'das_dual_simulation_easy.mat'))\n",
    "rec_apact = load_mat(os.path.join(results_path, 'apact_simulation_easy.mat'))\n",
    "rec_deconv = load_mat(os.path.join(results_path, 'deconv_simulation_easy.mat'))\n",
    "rec_jr = load_mat(os.path.join(results_path, 'jr_simulation_easy.mat'))    \n",
    "rec_deconv_onehot = load_mat(os.path.join(results_path, 'deconv_onehot_simulation_easy.mat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[IP_img, gt, rec_das, rec_das_dual, rec_apact, rec_deconv, rec_jr, rec_deconv_onehot] = \\\n",
    "    [standardize(img) for img in [IP_img, gt, rec_das, rec_das_dual, rec_apact, rec_deconv, rec_jr, rec_deconv_onehot]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = [(335, 300, 100, 100, 'green'), (380, 60, 100, 100,'blue'), (212, 146, 100, 200, 'red')]\n",
    "\n",
    "fig = plt.figure(figsize=(18.5, 17))\n",
    "gs = gridspec.GridSpec(10, 12)\n",
    "# norm = matplotlib.colors.Normalize(vmax=1, vmin=0)\n",
    "norm = Normalize(vmax=5, vmin=-1)\n",
    "for idx, (rec_full, method) in enumerate(zip([IP_img, rec_das, rec_das_dual, rec_apact, rec_deconv, rec_jr], \\\n",
    "                                             ['Ground Truth', 'Conventional DAS', 'Dual SoS DAS', 'APACT', 'Ours (True SoS)', 'Ours (Reconstructed SoS)'])):\n",
    "    ax = plt.subplot(gs[(idx//3)*5:(idx//3)*5+4,(idx%3)*4:(idx%3+1)*4])\n",
    "    if idx == 0:\n",
    "        plt.imshow(IP_img, cmap='gray', norm=Normalize(vmax=IP_img.max(), vmin=IP_img.min()))\n",
    "    else:\n",
    "        plt.imshow(rec_full, cmap='gray', norm=norm)\n",
    "    plt.title(method, fontsize=19)\n",
    "    if idx > 0:\n",
    "        plt.title('PSNR={:.2f}'.format(psnr(IP_img, rec_full, data_range=10)), loc='left', x=0.02, y=0.93, fontsize=15, color='white')\n",
    "        plt.title('SSIM={:.3f}'.format(ssim(IP_img, rec_full, data_range=10)), loc='right', x=0.98, y=0.93, fontsize=15, color='white')\n",
    "    plt.axis('off')\n",
    "    if idx % 3 == 2:\n",
    "        cax = fig.add_axes([ax.get_position().x1+0.01, ax.get_position().y0, 0.015, ax.get_position().height])\n",
    "        cb = plt.colorbar(cax=cax)\n",
    "    for k, (x, y, h, w, color) in enumerate(patches):\n",
    "        rect = plt.Rectangle((y, x), w, h, fill=False, edgecolor=color, linewidth=1.6, linestyle='--')\n",
    "        ax.add_patch(rect)\n",
    "        ax2 = plt.subplot(gs[(idx//3)*5+4:(idx//3)*5+5,(idx%3)*4+k:(idx%3)*4+k+1+(k==2)])\n",
    "        plt.imshow(rec_full[x:x+h, y:y+w], cmap='gray', norm=norm)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        for loc in ['bottom', 'top', 'left', 'right']:\n",
    "            ax2.spines[loc].set_color(color)\n",
    "            ax2.spines[loc].set_linewidth(2)\n",
    "            ax2.spines[loc].set_linestyle('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave(os.path.join('../figures', 'rec_das_simulation.png'), rec_das, cmap='gray', vmin=-1, vmax=5)\n",
    "plt.imsave(os.path.join('../figures', 'rec_jr_simulation.png'), rec_jr, cmap='gray', vmin=-1, vmax=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 4.5))\n",
    "for idx, (rec_full, attention) in enumerate(zip([rec_deconv, rec_deconv_onehot], ['Uniform', 'Onehot'])):\n",
    "        ax = plt.subplot(1,2,idx+1)\n",
    "        plt.imshow(rec_full, cmap='gray', norm=norm)\n",
    "        plt.title(attention, fontsize=20)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
