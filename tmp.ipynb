{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from utils.data import load_mat\n",
    "# from models.DAS import DAS\n",
    "# from kwave.utils import *\n",
    "from kwave.ktransducer import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_path = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True]\n",
      " [ True  True  True False]\n",
      " [ True  True  True  True]]\n",
      "[0 1 0 1 0 1 0 0 1 0 1]\n",
      "tensor([[0, 0, 0, 0],\n",
      "        [1, 1, 1, 1],\n",
      "        [2, 2, 2, 2]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m id_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(id_t)\n\u001b[0;32m---> 16\u001b[0m id_travel \u001b[38;5;241m=\u001b[39m \u001b[43mid_t\u001b[49m\u001b[43m[\u001b[49m\u001b[43mid_val\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m     18\u001b[0m related \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m)) \u001b[38;5;66;03m# [N HW]\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "sino = np.array([[1, 2],\n",
    "                 [3, 4],\n",
    "                 [5, 6]]) # [N L], intensity\n",
    "id = np.array([[0, 1, 0, 1],\n",
    "              [0, 1, 0, 2],\n",
    "              [0, 1, 0, 1]]) # [N HW], L\n",
    "id_val = id <= 1\n",
    "print(id_val)\n",
    "id_ravel= id[id_val].ravel() # N\n",
    "print(id_ravel)\n",
    "id_t = np.array([[0, 0, 0, 0],\n",
    "                 [1, 1, 1, 1],\n",
    "                 [2, 2, 2, 2]]) # N\n",
    "id_t = torch.arange(3).view(3,1).repeat(1, 4)\n",
    "print(id_t)\n",
    "id_travel = id_t[id_val].ravel()\n",
    "\n",
    "related = np.zeros((3, 4)) # [N HW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 1., 2.],\n",
       "       [3., 4., 3., 0.],\n",
       "       [5., 6., 5., 6.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related[id_val] = sino[id_t[id_val], id[id_val]]\n",
    "related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class DAS(nn.Module):\n",
    "    def __init__(self, R_ring, T_sample, v0, x_vec, y_vec, d_delay=0, ring_error=0):\n",
    "        super(DAS, self).__init__()\n",
    "        self.R_ring = R_ring\n",
    "        self.T_sample = T_sample\n",
    "        self.v0 = v0\n",
    "        self.x_vec = torch.tensor(x_vec).view(1, -1, 1)\n",
    "        self.y_vec = torch.tensor(y_vec).view(1, 1, -1)\n",
    "        print(self.x_vec.shape, self.y_vec.shape)\n",
    "        self.ring_error = torch.tensor(ring_error)\n",
    "\n",
    "    def forward(self, sinogram, d_delay=0):\n",
    "        N_transducer, H, W = sinogram.shape[0], self.x_vec.shape[1], self.y_vec.shape[2]\n",
    "        \n",
    "        angle_transducer = 2 * torch.pi / N_transducer * (torch.arange(N_transducer) + 1).view(-1, 1, 1)\n",
    "        x_transducer = self.R_ring * torch.sin(angle_transducer - torch.pi)\n",
    "        y_transducer = self.R_ring * torch.cos(angle_transducer - torch.pi)\n",
    "        distance_to_transducer = torch.sqrt((x_transducer - self.x_vec)**2 + (y_transducer - self.y_vec)**2) - d_delay + self.ring_error\n",
    "        id = torch.round(distance_to_transducer / (self.v0 * self.T_sample))\n",
    "        id_val = (id >= 0) * (id < sinogram.shape[1])\n",
    "        \n",
    "        related_data = torch.zeros((N_transducer, H, W), device=sinogram.device)\n",
    "        print(related_data.shape)\n",
    "        print(id.shape)\n",
    "        id_t = torch.arange(N_transducer).view(N_transducer,1,1).repeat(1,H,W)\n",
    "        print(id_t.shape)\n",
    "        related_data[id_val] = sinogram[id_t[id_val].int(), id[id_val].int()]\n",
    "        \n",
    "        return related_data.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinogram_uniform = load_mat(os.path.join(data_path, 'sinogram_simulation_uniform.mat'))\n",
    "sinogram_uniform = torch.from_numpy(sinogram_uniform).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx, Ny = 800, 800\n",
    "R_ring = 0.05   # Radius of the ring array [m].\n",
    "dx, dy = 4e-5, 4e-5\n",
    "kgrid = kWaveGrid([Nx, Ny], [dx, dy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 800, 1]) torch.Size([1, 1, 800])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DAS()"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DAS(0.05, 1/(40e6), 1508, kgrid.x_vec[:], kgrid.y_vec[:])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 800, 800])\n",
      "torch.Size([512, 800, 800])\n",
      "torch.Size([512, 800, 800])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.44 GiB. GPU 0 has a total capacty of 10.75 GiB of which 1020.69 MiB is free. Process 154574 has 626.00 MiB memory in use. Including non-PyTorch memory, this process has 9.14 GiB memory in use. Of the allocated memory 7.36 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msinogram_uniform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/.conda/envs/pact/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pact/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[114], line 30\u001b[0m, in \u001b[0;36mDAS.forward\u001b[0;34m(self, sinogram, d_delay)\u001b[0m\n\u001b[1;32m     28\u001b[0m id_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(N_transducer)\u001b[38;5;241m.\u001b[39mview(N_transducer,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m,H,W)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(id_t\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mrelated_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mid_val\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m sinogram[id_t[id_val]\u001b[38;5;241m.\u001b[39mint(), \u001b[38;5;28mid\u001b[39m[id_val]\u001b[38;5;241m.\u001b[39mint()]\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m related_data\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.44 GiB. GPU 0 has a total capacty of 10.75 GiB of which 1020.69 MiB is free. Process 154574 has 626.00 MiB memory in use. Including non-PyTorch memory, this process has 9.14 GiB memory in use. Of the allocated memory 7.36 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "img = model(sinogram_uniform)\n",
    "\n",
    "plt.imshow(img.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
